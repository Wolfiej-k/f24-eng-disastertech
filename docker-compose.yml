services:
  app:
    build:
      context: .
      dockerfile: app.Dockerfile
    container_name: frontend
    environment:
      - NODE_ENV=development
      - WATCHPACK_POLLING=true
    ports:
      - '3000:3000'
    depends_on:
      - api
  
  api:
    build:
      context: .
      dockerfile: api.Dockerfile
    container_name: backend
    environment:
      - POSTGRES_USER=t4sg
      - POSTGRES_PASSWORD=disaster-tech-labs
      - POSTGRES_DB=offline-ai
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
    ports:
      - '4000:4000'
    depends_on:
      - postgres
      - llama

  # https://github.com/ggerganov/llama.cpp/tree/master/examples/server#usage
  llama:
    image: ghcr.io/ggerganov/llama.cpp:server
    container_name: llama
    environment:
      - LLAMA_ARG_MODEL_URL=https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_L.gguf
      - LLAMA_ARG_MODEL=/models/llama.gguf
      - LLAMA_ARG_CTX_SIZE=4096
      - LLAMA_ARG_PORT=8080
    volumes:
      - models:/models
    
  # https://github.com/pgvector/pgvector?tab=readme-ov-file#additional-installation-methods
  postgres:
    image: pgvector/pgvector:pg17
    container_name: database
    environment:
      - POSTGRES_PASSWORD=disaster-tech-labs
      - POSTGRES_DB=offline-ai
      - POSTGRES_HOST=postgres
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./setup.sql:/docker-entrypoint-initdb.d/setup.sql

volumes:
  models:
  pgdata: